{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "380f031d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import sys,os\n",
    "from os.path import join\n",
    "sys.path.insert(0, '/home/monte.flora/python_packages/scikit-explain/')\n",
    "import skexplain \n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../../../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from src.common.util import subsampler, normalize_importance, compute_sage\n",
    "from sklearn.datasets import make_classification\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d2d26b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(N=5000):\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "\n",
    "    # Generate random values for two features\n",
    "    feature1 = np.random.rand(N)\n",
    "    feature2 = np.random.rand(N)\n",
    "\n",
    "    # Generate the interaction term by multiplying the two features\n",
    "    interaction = feature1 * feature2\n",
    "\n",
    "    # Generate the target variable (dependent variable) as a linear combination of features and interaction\n",
    "    y = 0 * feature1 + 0 * feature2 + 10 * interaction \n",
    "\n",
    "    # Create a DataFrame to hold the dataset\n",
    "    X = pd.DataFrame({'Feature 1': feature1, 'Feature 2': feature2})\n",
    "\n",
    "    est = RandomForestRegressor(max_features=None).fit(X,y)\n",
    "    #est = LinearRegression().fit(X,y)\n",
    "    \n",
    "    explainer = skexplain.ExplainToolkit(('LR', est), X=X, y=y)\n",
    "    \n",
    "    return explainer, X\n",
    "\n",
    "explainer, X = create_model()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2f369246",
   "metadata": {},
   "source": [
    "pd_1d = explainer.pd(features='all', n_bins=10, n_bootstrap=5)\n",
    "pd_2d = explainer.pd(features='all_2d', n_bins=10, n_bootstrap=5)\n",
    "results = explainer.friedman_h_stat(pd_1d, pd_2d, features=[('Feature 1', 'Feature 2')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb85f6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the H-statistics\n",
    "def compute_H2jk(PD_jk, PD_j, PD_k):\n",
    "\n",
    "    n_boot = len(PD_j)\n",
    "    h_stat = np.zeros((n_boot))\n",
    "    \n",
    "    for i in range(n_boot):\n",
    "        numerator = np.sum(np.square(PD_jk[i] - PD_j[i] - PD_k[i]))\n",
    "        denominator = np.sum(np.square(PD_jk[i]))\n",
    "\n",
    "        h_stat[i] = np.sqrt(numerator / denominator)\n",
    "\n",
    "    return h_stat\n",
    "\n",
    "def h_squared_shap(explain_vals, X, features, n_bins=10):\n",
    "    \n",
    "    feature_vals_1 = X[features[0]].values\n",
    "    feature_vals_2 = X[features[1]].values\n",
    "    \n",
    "    # Define the bins\n",
    "    bins_1 = np.unique(\n",
    "                np.percentile(feature_vals_1, np.linspace(0.0, 100.0, n_bins + 1), method=\"lower\"\n",
    "                ))\n",
    "    bins_2 = np.unique(\n",
    "                np.percentile(feature_vals_2, np.linspace(0.0, 100.0, n_bins + 1), method=\"lower\"\n",
    "                ))\n",
    "\n",
    "    # Get the bin number for each point\n",
    "    inds_1 = np.clip(np.digitize(feature_vals_1, bins_1, right=True) - 1, 0, None)\n",
    "    inds_2 = np.clip(np.digitize(feature_vals_2, bins_2, right=True) - 1, 0, None)\n",
    "\n",
    "    # Initialize arrays to hold the average explainability values and interaction values\n",
    "    mean_explain_vals = np.full((n_bins, n_bins), np.nan)\n",
    "    sum_explain_vals = np.full((n_bins, n_bins), np.nan)\n",
    "    interact_vals = np.full((n_bins, n_bins), np.nan)\n",
    "\n",
    "    # Compute the average explainability values and interaction values in each bin\n",
    "    for i in range(n_bins):\n",
    "        for j in range(n_bins):\n",
    "            vals_in_bin = explain_vals[(inds_1 == i) & (inds_2 == j)]\n",
    "            if vals_in_bin.size > 0:\n",
    "                # Approx first order effect\n",
    "                mean_explain_vals[i, j] = np.nanmean(vals_in_bin)\n",
    "                # Full effect.\n",
    "                sum_explain_vals[i, j] = np.nansum(vals_in_bin)\n",
    "                # Higher order effect.\n",
    "                interact_vals[i, j] = np.nanmean(np.abs(vals_in_bin - mean_explain_vals[i, j]))\n",
    "\n",
    "    H_squared = np.nansum(interact_vals**2) / np.nansum(sum_explain_vals**2) \n",
    "                \n",
    "    return np.sqrt(H_squared)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "92097bf1",
   "metadata": {},
   "source": [
    "PD_jk = pd_2d['Feature 1__Feature 2__LR__pd'].values\n",
    "PD_j = pd_1d['Feature 1__LR__pd'].values\n",
    "PD_k = pd_1d['Feature 2__LR__pd'].values\n",
    "\n",
    "compute_H2jk(PD_jk, PD_j, PD_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c88b1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exact explainer: 5001it [02:12, 36.21it/s]                                                                                                                                                         \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'n_bins' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m shap \u001b[38;5;241m=\u001b[39m explainer\u001b[38;5;241m.\u001b[39mlocal_attributions(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshap\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m features \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeature 1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeature 2\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 4\u001b[0m \u001b[43mh_squared_shap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 22\u001b[0m, in \u001b[0;36mh_squared_shap\u001b[0;34m(explain_values, X, features)\u001b[0m\n\u001b[1;32m     18\u001b[0m feature_vals_2 \u001b[38;5;241m=\u001b[39m X[features[\u001b[38;5;241m1\u001b[39m]]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Define the bins\u001b[39;00m\n\u001b[1;32m     21\u001b[0m bins_1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(\n\u001b[0;32m---> 22\u001b[0m             np\u001b[38;5;241m.\u001b[39mpercentile(feature_vals_1, np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m100.0\u001b[39m, \u001b[43mn_bins\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlower\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     23\u001b[0m             ))\n\u001b[1;32m     24\u001b[0m bins_2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(\n\u001b[1;32m     25\u001b[0m             np\u001b[38;5;241m.\u001b[39mpercentile(feature_vals_2, np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m100.0\u001b[39m, n_bins \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlower\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     26\u001b[0m             ))\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Get the bin number for each point\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n_bins' is not defined"
     ]
    }
   ],
   "source": [
    "shap = explainer.local_attributions(method='shap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c69d204c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'method' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m features \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeature 1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeature 2\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m \u001b[43mh_squared_shap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 40\u001b[0m, in \u001b[0;36mh_squared_shap\u001b[0;34m(explain_vals, X, features, n_bins)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_bins):\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_bins):\n\u001b[0;32m---> 40\u001b[0m         vals_in_bin \u001b[38;5;241m=\u001b[39m \u001b[43mexplain_vals\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43minds_1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43minds_2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m vals_in_bin\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     42\u001b[0m             \u001b[38;5;66;03m# Approx first order effect\u001b[39;00m\n\u001b[1;32m     43\u001b[0m             mean_explain_vals[i, j] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnanmean(vals_in_bin)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'method' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "features = ['Feature 1', 'Feature 2']\n",
    "h_squared_shap(shap.values, X, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e1ac9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
