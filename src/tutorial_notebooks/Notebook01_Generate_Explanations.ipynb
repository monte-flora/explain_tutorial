{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca37fcf2",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/github/monte-flora/explain_tutorial/blob/main/src/tutorial_notebooks/Notebook01_Generate_Explanations.ipynb)\n",
    "\n",
    "\n",
    "## Generate the Explainability Output\n",
    "\n",
    "In this notebook, we compute the explainability output used in the paper. The methods include:\n",
    "1. [Accumulated Local Effects (ALE)](https://christophm.github.io/interpretable-ml-book/ale.html)  \n",
    "2. [SHAP (Shapley Additive Explanations)](https://christophm.github.io/interpretable-ml-book/shap.html)\n",
    "3. [SAGE (Shapley Additive Global Explanations)](https://iancovert.com/blog/understanding-shap-sage/)\n",
    "\n",
    "For more details on the scikit-explain methods used here and more that we could not cover, there are more [tutorial notebooks on the github page](https://github.com/monte-flora/scikit-explain/tree/master/tutorial_notebooks)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d86bba",
   "metadata": {},
   "source": [
    "## A Machine Learning Explainability Tutorial for Atmospheric Sciences\n",
    "\n",
    "This article covers multiple topics in explainability, including definition of key terms. Some of the discussion are briefly reiterated here. \n",
    "\n",
    "\n",
    "\n",
    "1. **Interpretability versus Explainability**\n",
    "    - *Interpretability*: the degree to which an entire model and its components can be understood without additional methods.\n",
    "    - *Explainability*:  the degree to which any partially interpretable or uninterpretable model (i.e., black boxes) can be approximately understood through post hoc methods (e.g., verification, visualizations of important features, or learned relationships).\n",
    "    \n",
    "2. **Global versus Local Explainability**: \n",
    "    - *Global* : How does the trained model as a whole make predictions? How do components of the model affect the predictions?\n",
    "    - *Local*: Why did the model make a certain prediction for a specific set of examples?\n",
    "    \n",
    "    \n",
    "3. **Explainability method types**: \n",
    "    - *Feature Relevance and Feature Importance* : The ranking of features or sets of features by how much they contribute to a model’s output or its quality\n",
    "    - *Featue Effects* : The expected functional relationship between a feature (or set of features) and an ML model’s output\n",
    "    - *Feature Interactions*: How a given feature’s effect is dependent on other features and the strength of that effect \n",
    "    \n",
    "4. **Feature Relevance versus Importance**\n",
    "\n",
    "    - *Relevance* : How the input effects the model output.\n",
    "    - *Importance* : How the inputs effects the model performance. \n",
    "    \n",
    "5. **Model-Specific Importance versus Model-Agnostic Importance**\n",
    "\n",
    "    - *Model-Specific* : How important is this feature (or set of features) to this particular model, given this particular dataset? \n",
    "    \n",
    "    - *Model-Agnostic* : How important is this feature (or set of features) to any well-performing model, potentially regardless of the particular dataset. \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "raw",
   "id": "10fbd3c5-b035-48a7-98f9-6f2d6f58aef9",
   "metadata": {},
   "source": [
    "# For the tutorial notebooks, clone these two repos: \n",
    "\n",
    "git clone https://github.com/monte-flora/explain_tutorial\n",
    "\n",
    "git clone https://github.com/monte-flora/scikit-explain\n",
    "\n",
    "\n",
    "# For a clean environment: \n",
    "\n",
    "conda create --name skexplain python=3.10 scikit-explain numpy=1.22.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c6c5d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def using_colab():\n",
    "    try:\n",
    "        import google.colab\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffd075ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "# Constants. \n",
    "N_BOOTSTRAP = 10\n",
    "N_BINS = 5\n",
    "# Colab only has 2 CPUs, so thats the default here. If you have access to more CPUs\n",
    "# Feel free to increase N_JOBS. The closer you are to number of features greatly decreases\n",
    "# the runtime. \n",
    "N_JOBS = 2\n",
    "GLOBAL_SIZE = 5000\n",
    "LOCAL_SIZE = 10\n",
    "EVALUATION_FN = 'norm_aupdc'\n",
    "##########################\n",
    "DATASET = 'road_surface'\n",
    "##########################\n",
    "\n",
    "if not os.path.exists('results'):\n",
    "    os.mkdir('results')\n",
    "\n",
    "if using_colab(): \n",
    "    BASE_PATH       = os.getcwd()\n",
    "else:\n",
    "    # If you are not using Goolge Colab, then you need to define \n",
    "    # your own base path where the explainability results will be stored. \n",
    "    #BASE_PATH = '/Users/Home/tutorial_files'\n",
    "    BASE_PATH = os.getcwd()\n",
    "    \n",
    "RESULTS_PATH    = os.path.join(BASE_PATH, 'results')\n",
    "DATA_BASE_PATH  = os.path.join(BASE_PATH, 'datasets')\n",
    "MODEL_BASE_PATH = os.path.join(BASE_PATH, 'models')\n",
    "\n",
    "if not os.path.exists(RESULTS_PATH):\n",
    "    os.makedirs(RESULTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d72c1020",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os \n",
    "from glob import glob\n",
    "if using_colab():\n",
    "    # When using Google Colab, need to clone the explain_tutorial repo\n",
    "    # Otherwise, the code assumes you are running these notebooks\n",
    "    # in their original directory structure. \n",
    "    try:\n",
    "        !git clone https://github.com/monte-flora/explain_tutorial\n",
    "    except:\n",
    "        print('explain_tutorial has already been cloned!')\n",
    "    sys.path.append('explain_tutorial')   \n",
    "    from src.io.colab_io import GoogleDriveIO\n",
    "else:\n",
    "    from os.path import dirname\n",
    "    path = dirname(dirname(os.getcwd()))\n",
    "    sys.path.append(path)\n",
    "\n",
    "# Download data from Google drive\n",
    "if using_colab():\n",
    "    DATASET_PATHS = {'lightning' : '/content/datasets/lightning_dataset.csv', \n",
    "              'road_surface' : '/content/datasets/road_surface_dataset.csv', \n",
    "              'severe_wind' : '/content/datasets/severe_wind_dataset.csv', \n",
    "     }\n",
    "    MODEL_PATHS = {                  \n",
    "              'lightning' : '/content/models/NN_classification.joblib', \n",
    "              'road_surface' : '/content/models/JTTI_ProbSR_RandomForest.pkl', \n",
    "              'severe_wind' : '/content/models/LogisticRegression_wind_severe_0km_None_first_hour_realtime.joblib', \n",
    "              }\n",
    "\n",
    "    paths_dict = {f'{DATASET} dataset' :  DATASET_PATHS[DATASET], \n",
    "                  f'{DATASET} model' :  MODEL_PATHS[DATASET], \n",
    "                  }\n",
    "    \n",
    "    downloader = GoogleDriveIO()\n",
    "    # Make a 'datasets' and 'models' directories\n",
    "    if not os.path.exists('datasets'):\n",
    "        os.mkdir('datasets')\n",
    "    if not os.path.exists('models'):\n",
    "        os.mkdir('models')\n",
    "    \n",
    "    for title in paths_dict.keys():\n",
    "        downloader.download(title, paths_dict[title])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1cd95c",
   "metadata": {},
   "source": [
    "#### Install different python packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dc94ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neccesary packages to load the ML models from pickle\n",
    "%pip install scikit-explain==0.1.4 sage-importance imbalanced-learn daal4py scikit-learn==1.0.2 scikit-learn-intelex bayeshist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a401b35",
   "metadata": {},
   "source": [
    "#### Import python packages (internal and third party)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba4f8bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skexplain \n",
    "from skexplain.common.importance_utils import to_skexplain_importance\n",
    "from src.io.io import load_data_and_model\n",
    "from src.common.util import subsampler, normalize_importance, compute_sage\n",
    "\n",
    "import pickle\n",
    "import shap\n",
    "import itertools\n",
    "import numpy as np\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d212d106",
   "metadata": {},
   "source": [
    "#### Setting the user constants (paths, parameters, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42a89d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function compute_shap at 0x15839d870>\n",
      "<function compute_ale at 0x15839dd80>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALE Numerical Features: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [03:06<00:00,  6.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function compute_sage_ at 0x15839d6c0>\n",
      "PermutationEstimator will use 2 jobs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e69a95ef1a794589b1216325f48f9eb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function compute_group_sage at 0x15839d900>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b656d62667084db5a2b4e2703d997bc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time \n",
    "# Compute ALE \n",
    "def compute_ale(explainer, dataset, est_name, **kwargs): \n",
    "    ale = explainer.ale(features='all', n_bootstrap=N_BOOTSTRAP, n_bins=N_BINS, n_jobs=N_JOBS)\n",
    "    # Save ALE results (as netcdf file)\n",
    "    explainer.save(os.path.join(RESULTS_PATH, f'ale_{dataset}.nc'), ale, encoding=None)\n",
    "\n",
    "\n",
    "# Compute Shapely Additive Explanation (SHAP)\n",
    "def compute_shap(explainer, dataset, est_name, **kwargs):\n",
    "    X = kwargs['X']\n",
    "    features = kwargs['X'].columns\n",
    "    results = explainer.local_attributions('shap', \n",
    "                                       shap_kws={'masker' : \n",
    "                                      shap.maskers.Partition(X, max_samples=50, \n",
    "                                                             clustering=\"correlation\"), \n",
    "                                     'algorithm' : 'permutation'})\n",
    "\n",
    "\n",
    "    shap_rank = to_skexplain_importance(results[f'shap_values__{est_name}'].values, \n",
    "                                     estimator_name=est_name, \n",
    "                                     feature_names=features, \n",
    "                                     method ='shap_sum', \n",
    "                                     normalize=False    \n",
    "                                       )\n",
    "\n",
    "    # Sum the SHAP values for each feature and then save results. \n",
    "    explainer.save(os.path.join(RESULTS_PATH, f'shap_{dataset}.nc'), results, encoding=None)\n",
    "    explainer.save(os.path.join(RESULTS_PATH, f'shap_rank_{dataset}.nc'), shap_rank, encoding=None)\n",
    "\n",
    "# Compute SAGE\n",
    "def compute_sage_(explainer, dataset, est_name, **kwargs):\n",
    "    estimator = explainer.estimators[est_name]\n",
    "    \n",
    "    X = explainer.X\n",
    "    y = explainer.y\n",
    "    X_orig = kwargs['X']\n",
    "    \n",
    "    features = kwargs['X'].columns\n",
    "    sage_values = compute_sage(estimator, X.values, y, X_orig, n_jobs = N_JOBS)\n",
    "    sage_rank = to_skexplain_importance(sage_values,\n",
    "                                     estimator_name=est_name, \n",
    "                                     feature_names=features, \n",
    "                                     method = 'sage', \n",
    "                                     normalize=False  \n",
    "                                       )\n",
    "\n",
    "    # Sum the SAGE values for each feature and then save results. \n",
    "    explainer.save(os.path.join(RESULTS_PATH, f'sage_{dataset}.nc'), sage_rank, encoding=None)\n",
    "\n",
    "\n",
    "# Compute Grouped SAGE\n",
    "def compute_group_sage(explainer, dataset,  est_name, **kwargs):\n",
    "    \n",
    "    X = explainer.X\n",
    "    feature_groups = kwargs['groups']\n",
    "    # Group indices\n",
    "    groups = []\n",
    "    cols = list(X.columns)\n",
    "    features = []\n",
    "    for key, group in feature_groups.items():\n",
    "        ind_list = []\n",
    "        for feature in group:\n",
    "            ind_list.append(cols.index(feature))\n",
    "        groups.append(ind_list)\n",
    "        features.append(key)  \n",
    "    \n",
    "    estimator = explainer.estimators[est_name]\n",
    "    \n",
    "    y = explainer.y\n",
    "    X_orig = kwargs['X']\n",
    "    \n",
    "    sage_values = compute_sage(estimator, X.values, y, X_orig, groups=groups)\n",
    "    sage_rank = to_skexplain_importance(sage_values,\n",
    "                                     estimator_name=est_name, \n",
    "                                     feature_names=features, \n",
    "                                     method = 'sage', \n",
    "                                     normalize=False  \n",
    "                                       )\n",
    "\n",
    "    # Sum the SAGE values for each feature and then save results. \n",
    "    explainer.save(os.path.join(RESULTS_PATH, f'grouped_sage_{dataset}.nc'), sage_rank, encoding=None)\n",
    "    \n",
    "global_methods = [compute_ale, compute_sage_, compute_group_sage,]\n",
    "local_methods = [compute_shap]\n",
    "\n",
    "# Load model and data.\n",
    "model, X, y, groups = load_data_and_model(DATASET, DATA_BASE_PATH, MODEL_BASE_PATH, \n",
    "                                     return_groups=True)\n",
    "est_name = model[0]\n",
    "    \n",
    "# Subsample the dataset with GLOBAL_SIZE samples for the global methods. \n",
    "X_sub, y_sub = subsampler(X,y, GLOBAL_SIZE)\n",
    "\n",
    "# Initialize the explainer. \n",
    "global_explainer = skexplain.ExplainToolkit(model, X_sub, y_sub) \n",
    "    \n",
    "# Subsample the GLOBAL_SIZE samples with LOCAL_SIZE samples for the local methods\n",
    "X_local, y_local = subsampler(X_sub, y_sub, LOCAL_SIZE)\n",
    "local_explainer = skexplain.ExplainToolkit(model, X_local, y_local)\n",
    "    \n",
    "for method in local_methods:\n",
    "    print(method)\n",
    "    method(local_explainer, DATASET, est_name, X=X)\n",
    "\n",
    "for method in global_methods:\n",
    "    print(method)\n",
    "    method(global_explainer, DATASET, est_name, X=X, model=model, groups=groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc99f485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the explainability results to Google drive for Notebook02_Explainability_Tutorial.\n",
    "if using_colab():\n",
    "    uploader= GoogleDriveIO()\n",
    "    results_paths = glob('results/*')\n",
    "\n",
    "    for path in results_paths:\n",
    "        print(f'Uploading {path} dataset to Google Drive...')\n",
    "        uploader.upload(path, title=os.path.basename(path).replace('.nc', ''))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
